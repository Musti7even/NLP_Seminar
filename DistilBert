
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer

tokenizer2 = AutoTokenizer.from_pretrained("lvwerra/distilbert-imdb")

model2 = AutoModelForSequenceClassification.from_pretrained("lvwerra/distilbert-imdb")

from datasets import load_dataset
import numpy as np
import evaluate

dataset = load_dataset("imdb", split="test")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
    
def tokenize_function2(examples):
    return tokenizer2(examples["text"], padding="max_length", truncation=True)


tokenized_datasets2 = dataset.map(tokenize_function2, batched=True)
test_dataset_processed_preModel = tokenized_datasets2.shuffle(seed=42)

model2.eval()

trainer2 = Trainer(
    model=model2,
    compute_metrics=compute_metrics,
)

trainer2.predict(test_dataset_processed_preModel)
